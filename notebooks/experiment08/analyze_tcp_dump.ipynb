{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa87e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scapy.all as scapy\n",
    "from scapy.layers.inet import IP, TCP\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from collections import defaultdict\n",
    "\n",
    "# Global Configuration for your timezone\n",
    "LOCAL_OFFSET = -3  # GMT-3\n",
    "LOCAL_TZ = timezone(timedelta(hours=LOCAL_OFFSET))\n",
    "\n",
    "# Define your experiment window (Local time)\n",
    "START_TIME = \"2025-12-26 14:15:00\"\n",
    "END_TIME   = \"2025-12-26 16:25:00\"\n",
    "\n",
    "class ExperimentAnalyzer:\n",
    "    def __init__(self, directory, start_str, end_str):\n",
    "        self.directory = directory\n",
    "        self.start_ts = datetime.strptime(start_str, \"%Y-%m-%d %H:%M:%S\") \\\n",
    "                            .replace(tzinfo=LOCAL_TZ).timestamp()\n",
    "        \n",
    "        self.end_ts = datetime.strptime(end_str, \"%Y-%m-%d %H:%M:%S\") \\\n",
    "                            .replace(tzinfo=LOCAL_TZ).timestamp()\n",
    "\n",
    "        print(f\"Filtering for UTC Range: {datetime.fromtimestamp(self.start_ts, tz=timezone.utc)}\")\n",
    "        \n",
    "        # State\n",
    "        self.all_packet_data = []\n",
    "        self.metrics = {\"resets\": 0, \"retrans\": 0, \"zeros\": 0}\n",
    "        self.pending_reqs = {}\n",
    "        self.flow_sequences = defaultdict(set)\n",
    "\n",
    "    def run_batch(self):\n",
    "        # Get all pcap files and sort them chronologically\n",
    "        files = sorted([f for f in os.listdir(self.directory) if f.endswith(\".pcap\")])\n",
    "        \n",
    "        for filename in files:\n",
    "            file_path = os.path.join(self.directory, filename)\n",
    "            \n",
    "            # Rough check: Parse timestamp from filename (e.g., experiment_capture_20251226_170306.pcap)\n",
    "            try:\n",
    "                file_start_str = \"_\".join(filename.split(\"_\")[2:4]).replace(\".pcap\", \"\")\n",
    "                file_start_ts = datetime.strptime(file_start_str, \"%Y%m%d_%H%M%S\").timestamp()\n",
    "                \n",
    "                # If file starts after our window, we can stop (since files are sorted)\n",
    "                if file_start_ts > self.end_ts:\n",
    "                    continue\n",
    "            except Exception:\n",
    "                pass # Fallback to processing if filename format differs\n",
    "\n",
    "            print(f\"Processing: {filename}...\")\n",
    "            self._process_file(file_path)\n",
    "\n",
    "        self._print_final_report()\n",
    "\n",
    "    def _process_file(self, file_path):\n",
    "        with scapy.PcapReader(file_path) as reader:\n",
    "            for pkt in reader:\n",
    "                if not pkt.haslayer(TCP): continue\n",
    "                \n",
    "                # Fine-grained timestamp filter\n",
    "                ts = float(pkt.time)\n",
    "                if ts < self.start_ts: continue\n",
    "                if ts > self.end_ts: break # Optimization: stop reading this file\n",
    "                \n",
    "                ip = pkt[IP]\n",
    "                tcp = pkt[TCP]\n",
    "                \n",
    "                # Logic for Kafka Filtering\n",
    "                if (ip.src == KAFKA_IP and tcp.sport == KAFKA_PORT) or \\\n",
    "                   (ip.dst == KAFKA_IP and tcp.dport == KAFKA_PORT):\n",
    "                    self._extract_metrics(ip, tcp, ts)\n",
    "\n",
    "    def _extract_metrics(self, ip, tcp, ts):\n",
    "        # 1. TCP Health\n",
    "        if tcp.flags & 0x04: self.metrics[\"resets\"] += 1\n",
    "        if tcp.window == 0: self.metrics[\"zeros\"] += 1\n",
    "        \n",
    "        # 2. Retransmissions\n",
    "        flow = (ip.src, ip.dst, tcp.sport, tcp.dport)\n",
    "        if len(tcp.payload) > 0:\n",
    "            if tcp.seq in self.flow_sequences[flow]:\n",
    "                self.metrics[\"retrans\"] += 1\n",
    "            else:\n",
    "                self.flow_sequences[flow].add(tcp.seq)\n",
    "\n",
    "        # 3. Kafka Correlation ID Matching\n",
    "        payload = bytes(tcp.payload)\n",
    "        if len(payload) > 12:\n",
    "            try:\n",
    "                if tcp.dport == KAFKA_PORT: # Request\n",
    "                    cid = int.from_bytes(payload[8:12], \"big\")\n",
    "                    self.pending_reqs[cid] = ts\n",
    "                elif tcp.sport == KAFKA_PORT: # Response\n",
    "                    cid = int.from_bytes(payload[4:8], \"big\")\n",
    "                    if cid in self.pending_reqs:\n",
    "                        lat = (ts - self.pending_reqs[cid]) * 1000\n",
    "                        self.all_packet_data.append({'type': 'kafka_lat', 'val': lat, 'ts': ts})\n",
    "                        del self.pending_reqs[cid]\n",
    "            except: pass\n",
    "\n",
    "        # 4. Jitter (IAT from Broker)\n",
    "        if ip.src == KAFKA_IP:\n",
    "            self.all_packet_data.append({'type': 'iat', 'val': ts, 'ts': ts})\n",
    "\n",
    "    def _print_final_report(self):\n",
    "        df = pd.DataFrame(self.all_packet_data)\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(f\"EXPERIMENT SUMMARY ({START_TIME} to {END_TIME})\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Resets: {self.metrics['resets']} | Retrans: {self.metrics['retrans']} | ZeroWindows: {self.metrics['zeros']}\")\n",
    "        \n",
    "        # 1. Get Inter-Arrival Times (IAT) in milliseconds\n",
    "        iat_series = df[df['type'] == 'iat']['val'].diff().dropna() * 1000\n",
    "        \n",
    "        # 2. Filter out idle gaps (e.g., any gap > 1000ms is considered 'app idleness', not network jitter)\n",
    "        # This prevents the 160s jitter you saw.\n",
    "        network_iats = iat_series[iat_series < 1000]\n",
    "        \n",
    "        if not network_iats.empty:\n",
    "            # 3. Calculate Average Jitter (Mean Absolute Deviation of successive IATs)\n",
    "            # This is closer to how Wireshark calculates it.\n",
    "            jitter = np.abs(network_iats.diff()).mean()\n",
    "        else:\n",
    "            jitter = 0\n",
    "\n",
    "        print(f\"Refined Network Jitter: {jitter:.4f} ms\")\n",
    "\n",
    "        # Kafka Latency Stats\n",
    "        k_lat = df[df['type'] == 'kafka_lat']['val']\n",
    "        if not k_lat.empty:\n",
    "            print(f\"Kafka Latency: Avg={k_lat.mean():.2f}ms, P95={k_lat.quantile(0.95):.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Config\n",
    "KAFKA_IP = \"167.71.21.92\"\n",
    "KAFKA_PORT = 32289\n",
    "DATA_DIR = \"../../data/raw/experiment08/tcp_dump_cloud\"\n",
    "\n",
    "analyzer = ExperimentAnalyzer(DATA_DIR, START_TIME, END_TIME)\n",
    "analyzer.run_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d189fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for UTC Range: 2025-12-26 17:15:00+00:00\n",
      "Processing: experiment_capture_20251226_133302.pcap...\n",
      "Processing: experiment_capture_20251226_170234.pcap...\n",
      "Processing: experiment_capture_20251226_171937.pcap...\n",
      "Processing: experiment_capture_20251226_173550.pcap...\n",
      "Processing: experiment_capture_20251226_175413.pcap...\n",
      "Processing: experiment_capture_20251226_180427.pcap...\n",
      "Processing: experiment_capture_20251226_182012.pcap...\n",
      "Processing: experiment_capture_20251226_183534.pcap...\n",
      "Processing: experiment_capture_20251226_185119.pcap...\n",
      "\n",
      "========================================\n",
      "EXPERIMENT SUMMARY (2025-12-26 14:15:00 to 2025-12-26 16:25:00)\n",
      "========================================\n",
      "Resets: 0 | Retrans: 0 | ZeroWindows: 0\n",
      "Refined Network Jitter: 46.4070 ms\n",
      "Kafka Latency: Avg=62.34ms, P95=93.85ms\n"
     ]
    }
   ],
   "source": [
    "# Global Config\n",
    "KAFKA_IP = \"172.16.208.242\"\n",
    "KAFKA_PORT = 31289\n",
    "DATA_DIR = \"../../data/raw/experiment08/tcp_dump_edge\"\n",
    "\n",
    "analyzer = ExperimentAnalyzer(DATA_DIR, START_TIME, END_TIME)\n",
    "analyzer.run_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9458d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PcapToParquetExporter:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.records = []\n",
    "        self.pending_reqs = {} # corr_id -> timestamp\n",
    "        self.syn_times = {}    # flow -> timestamp\n",
    "\n",
    "    def process(self):\n",
    "        files = sorted([f for f in os.listdir(self.directory) if f.endswith(\".pcap\")])\n",
    "        \n",
    "        for filename in files:\n",
    "            path = os.path.join(self.directory, filename)\n",
    "            print(f\"Exporting: {filename}\")\n",
    "            \n",
    "            with scapy.PcapReader(path) as reader:\n",
    "                for pkt in reader:\n",
    "                    if not pkt.haslayer(TCP) or not pkt.haslayer(IP):\n",
    "                        continue\n",
    "                        \n",
    "                    ip, tcp = pkt[IP], pkt[TCP]\n",
    "                    ts = float(pkt.time)\n",
    "                    \n",
    "                    # Filter for Kafka\n",
    "                    is_to_kafka = (ip.dst == KAFKA_IP and tcp.dport == KAFKA_PORT)\n",
    "                    is_from_kafka = (ip.src == KAFKA_IP and tcp.sport == KAFKA_PORT)\n",
    "                    \n",
    "                    if not (is_to_kafka or is_from_kafka):\n",
    "                        continue\n",
    "\n",
    "                    record = {\n",
    "                        \"timestamp\": ts,\n",
    "                        \"src_ip\": ip.src,\n",
    "                        \"dst_ip\": ip.dst,\n",
    "                        \"actual_msg_count\": 0,\n",
    "                        \"tcp_flags\": int(tcp.flags),\n",
    "                        \"window_size\": tcp.window,\n",
    "                        \"payload_len\": len(tcp.payload),\n",
    "                        \"rtt_ms\": None,\n",
    "                        \"kafka_lat_ms\": None,\n",
    "                        \"is_retransmission\": 0\n",
    "                    }\n",
    "\n",
    "                    # --- RTT Calculation (Network) ---\n",
    "                    if tcp.flags & 0x02: # SYN\n",
    "                        self.syn_times[(ip.src, tcp.sport)] = ts\n",
    "                    elif tcp.flags & 0x12: # SYN-ACK\n",
    "                        key = (ip.dst, tcp.dport)\n",
    "                        if key in self.syn_times:\n",
    "                            record[\"rtt_ms\"] = (ts - self.syn_times[key]) * 1000\n",
    "                            del self.syn_times[key]\n",
    "\n",
    "                    # --- Kafka Latency Calculation (App) ---\n",
    "                    payload = bytes(tcp.payload)\n",
    "                    if len(payload) > 12:\n",
    "                        try:\n",
    "                            if is_to_kafka:\n",
    "                                corr_id = int.from_bytes(payload[8:12], \"big\")\n",
    "                                self.pending_reqs[corr_id] = ts\n",
    "                            elif is_from_kafka:\n",
    "                                corr_id = int.from_bytes(payload[4:8], \"big\")\n",
    "                                if corr_id in self.pending_reqs:\n",
    "                                    record[\"kafka_lat_ms\"] = (ts - self.pending_reqs[corr_id]) * 1000\n",
    "                                    del self.pending_reqs[corr_id]\n",
    "                        except: pass\n",
    "\n",
    "                    self.records.append(record)\n",
    "\n",
    "        # Convert and Save\n",
    "        df = pd.DataFrame(self.records)\n",
    "        if not df.empty:\n",
    "            # 2. Sort by timestamp to ensure the rolling window is accurate\n",
    "            df = df.sort_values(\"timestamp\")\n",
    "            \n",
    "            # 4. Save to Parquet\n",
    "            df.to_parquet(OUTPUT_FILE, compression='snappy')\n",
    "            print(f\"Successfully saved {len(df)} records with throughput metrics to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab57801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting: experiment_capture_20251226_170306.pcap\n",
      "Exporting: experiment_capture_20251226_171043.pcap\n",
      "Exporting: experiment_capture_20251226_172005.pcap\n",
      "Exporting: experiment_capture_20251226_173533.pcap\n",
      "Exporting: experiment_capture_20251226_175124.pcap\n",
      "Exporting: experiment_capture_20251226_180530.pcap\n",
      "Exporting: experiment_capture_20251226_181957.pcap\n",
      "Exporting: experiment_capture_20251226_183605.pcap\n",
      "Exporting: experiment_capture_20251226_185436.pcap\n",
      "Successfully saved 304 records with throughput metrics to analyzed_network_metrics_cloud.parquet\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = \"analyzed_network_metrics_cloud.parquet\"\n",
    "KAFKA_IP = \"167.71.21.92\"\n",
    "KAFKA_PORT = 32289\n",
    "DATA_DIR = \"../../data/raw/experiment08/tcp_dump_cloud\"\n",
    "exporter = PcapToParquetExporter(DATA_DIR)\n",
    "exporter.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324a6cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting: experiment_capture_20251226_133302.pcap\n",
      "Exporting: experiment_capture_20251226_170234.pcap\n",
      "Exporting: experiment_capture_20251226_171937.pcap\n",
      "Exporting: experiment_capture_20251226_173550.pcap\n",
      "Exporting: experiment_capture_20251226_175413.pcap\n",
      "Exporting: experiment_capture_20251226_180427.pcap\n",
      "Exporting: experiment_capture_20251226_182012.pcap\n",
      "Exporting: experiment_capture_20251226_183534.pcap\n",
      "Exporting: experiment_capture_20251226_185119.pcap\n",
      "Successfully saved 269 records with throughput metrics to analyzed_network_metrics_edge.parquet\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = \"analyzed_network_metrics_edge.parquet\"\n",
    "KAFKA_IP = \"172.16.208.242\"\n",
    "KAFKA_PORT = 31289\n",
    "DATA_DIR = \"../../data/raw/experiment08/tcp_dump_edge\"\n",
    "exporter = PcapToParquetExporter(DATA_DIR)\n",
    "exporter.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd7d4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloud = pd.read_parquet(\"analyzed_network_metrics_cloud.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8372df39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "src_ip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dst_ip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "actual_msg_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tcp_flags",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "window_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "payload_len",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rtt_ms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kafka_lat_ms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_retransmission",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8072b77b-acc9-470f-98b0-5d93037200f8",
       "rows": [
        [
         "0",
         "1766768586.558754",
         "167.71.21.92",
         "172.17.0.5",
         "0",
         "18",
         "65535",
         "0",
         null,
         null,
         "0"
        ],
        [
         "1",
         "1766768586.558794",
         "172.17.0.5",
         "167.71.21.92",
         "0",
         "16",
         "502",
         "0",
         "0.0400543212890625",
         null,
         "0"
        ],
        [
         "2",
         "1766768586.558889",
         "172.17.0.5",
         "167.71.21.92",
         "0",
         "24",
         "502",
         "66",
         null,
         null,
         "0"
        ],
        [
         "3",
         "1766768586.700938",
         "167.71.21.92",
         "172.17.0.5",
         "0",
         "16",
         "32768",
         "0",
         null,
         null,
         "0"
        ],
        [
         "4",
         "1766768586.702199",
         "167.71.21.92",
         "172.17.0.5",
         "0",
         "24",
         "32768",
         "460",
         null,
         "143.3100700378418",
         "0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>actual_msg_count</th>\n",
       "      <th>tcp_flags</th>\n",
       "      <th>window_size</th>\n",
       "      <th>payload_len</th>\n",
       "      <th>rtt_ms</th>\n",
       "      <th>kafka_lat_ms</th>\n",
       "      <th>is_retransmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.766769e+09</td>\n",
       "      <td>167.71.21.92</td>\n",
       "      <td>172.17.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.766769e+09</td>\n",
       "      <td>172.17.0.5</td>\n",
       "      <td>167.71.21.92</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.766769e+09</td>\n",
       "      <td>172.17.0.5</td>\n",
       "      <td>167.71.21.92</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>502</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.766769e+09</td>\n",
       "      <td>167.71.21.92</td>\n",
       "      <td>172.17.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.766769e+09</td>\n",
       "      <td>167.71.21.92</td>\n",
       "      <td>172.17.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>32768</td>\n",
       "      <td>460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.31007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp        src_ip        dst_ip  actual_msg_count  tcp_flags  \\\n",
       "0  1.766769e+09  167.71.21.92    172.17.0.5                 0         18   \n",
       "1  1.766769e+09    172.17.0.5  167.71.21.92                 0         16   \n",
       "2  1.766769e+09    172.17.0.5  167.71.21.92                 0         24   \n",
       "3  1.766769e+09  167.71.21.92    172.17.0.5                 0         16   \n",
       "4  1.766769e+09  167.71.21.92    172.17.0.5                 0         24   \n",
       "\n",
       "   window_size  payload_len    rtt_ms  kafka_lat_ms  is_retransmission  \n",
       "0        65535            0       NaN           NaN                  0  \n",
       "1          502            0  0.040054           NaN                  0  \n",
       "2          502           66       NaN           NaN                  0  \n",
       "3        32768            0       NaN           NaN                  0  \n",
       "4        32768          460       NaN     143.31007                  0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d030d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge = pd.read_parquet(\"analyzed_network_metrics_edge.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d2bea64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "src_ip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dst_ip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "actual_msg_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tcp_flags",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "window_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "payload_len",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rtt_ms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kafka_lat_ms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_retransmission",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "273c994b-8b55-4316-882c-d379accf354a",
       "rows": [
        [
         "0",
         "1766755982.277094",
         "172.16.208.242",
         "172.17.0.4",
         "0",
         "24",
         "32768",
         "1398",
         null,
         null,
         "0"
        ],
        [
         "1",
         "1766755982.277127",
         "172.17.0.4",
         "172.16.208.242",
         "0",
         "16",
         "589",
         "0",
         null,
         null,
         "0"
        ],
        [
         "2",
         "1766755982.277129",
         "172.16.208.242",
         "172.17.0.4",
         "0",
         "24",
         "32768",
         "699",
         null,
         null,
         "0"
        ],
        [
         "3",
         "1766755982.320947",
         "172.17.0.4",
         "172.16.208.242",
         "0",
         "16",
         "611",
         "0",
         null,
         null,
         "0"
        ],
        [
         "4",
         "1766755982.452251",
         "172.17.0.4",
         "172.16.208.242",
         "0",
         "17",
         "611",
         "0",
         null,
         null,
         "0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>actual_msg_count</th>\n",
       "      <th>tcp_flags</th>\n",
       "      <th>window_size</th>\n",
       "      <th>payload_len</th>\n",
       "      <th>rtt_ms</th>\n",
       "      <th>kafka_lat_ms</th>\n",
       "      <th>is_retransmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.766756e+09</td>\n",
       "      <td>172.16.208.242</td>\n",
       "      <td>172.17.0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>32768</td>\n",
       "      <td>1398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.766756e+09</td>\n",
       "      <td>172.17.0.4</td>\n",
       "      <td>172.16.208.242</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.766756e+09</td>\n",
       "      <td>172.16.208.242</td>\n",
       "      <td>172.17.0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>32768</td>\n",
       "      <td>699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.766756e+09</td>\n",
       "      <td>172.17.0.4</td>\n",
       "      <td>172.16.208.242</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.766756e+09</td>\n",
       "      <td>172.17.0.4</td>\n",
       "      <td>172.16.208.242</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp          src_ip          dst_ip  actual_msg_count  tcp_flags  \\\n",
       "0  1.766756e+09  172.16.208.242      172.17.0.4                 0         24   \n",
       "1  1.766756e+09      172.17.0.4  172.16.208.242                 0         16   \n",
       "2  1.766756e+09  172.16.208.242      172.17.0.4                 0         24   \n",
       "3  1.766756e+09      172.17.0.4  172.16.208.242                 0         16   \n",
       "4  1.766756e+09      172.17.0.4  172.16.208.242                 0         17   \n",
       "\n",
       "   window_size  payload_len  rtt_ms  kafka_lat_ms  is_retransmission  \n",
       "0        32768         1398     NaN           NaN                  0  \n",
       "1          589            0     NaN           NaN                  0  \n",
       "2        32768          699     NaN           NaN                  0  \n",
       "3          611            0     NaN           NaN                  0  \n",
       "4          611            0     NaN           NaN                  0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edge.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streaming-pipeline (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
